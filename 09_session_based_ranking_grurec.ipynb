{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# 9) Session-based Ranking (GRU4Rec-style)"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\n%%capture\n!pip -q install --upgrade pip\n!pip -q install datasets transformers sentence-transformers faiss-cpu rank-bm25 torchmetrics scikit-learn lightgbm langdetect unidecode pandas matplotlib tqdm nltk"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\nimport numpy as np, torch, torch.nn as nn, torch.optim as optim\nfrom datasets import load_dataset\nfrom tqdm.auto import tqdm\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nnp.random.seed(42); torch.manual_seed(42)"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\nds = load_dataset(\"amazon_reviews_multi\",\"en\", split=\"train[:20%]\")\ndf = ds.to_pandas()[[\"reviewer_id\",\"product_id\"]].dropna()\nif \"reviewer_id\" not in df.columns:\n    df[\"reviewer_id\"] = df.index.astype(int) // 5\nseqs = []\nfor _,g in df.groupby(\"reviewer_id\"):\n    items = g[\"product_id\"].astype(str).tolist()\n    if len(items)>=5: seqs.append(items[:20])\nall_items = {p:i for i,p in enumerate(sorted(set([x for s in seqs for x in s])))}\nint_seqs = [[all_items[x] for x in s] for s in seqs]\nX, Y = [], []\nfor s in int_seqs:\n    for t in range(1, len(s)):\n        X.append(s[:t]); Y.append(s[t])\nmaxlen=15\nX = [x[-maxlen:] for x in X]\nXpad = np.zeros((len(X), maxlen), dtype=np.int64)\nfor i,seq in enumerate(X): Xpad[i,-len(seq):] = seq\nY = np.array(Y, dtype=np.int64)\nTR = int(0.8*len(Xpad)); I=len(all_items)"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\nclass GRURec(nn.Module):\n    def __init__(self, n_items, d=128):\n        super().__init__()\n        self.emb = nn.Embedding(n_items, d)\n        self.gru = nn.GRU(d, d, batch_first=True)\n        self.fc = nn.Linear(d, n_items)\n    def forward(self, x):\n        x = self.emb(x); h,_ = self.gru(x); return self.fc(h[:,-1,:])\n\nmodel = GRURec(I).to(device); opt=optim.AdamW(model.parameters(), lr=3e-3); loss=nn.CrossEntropyLoss()\nfor ep in range(3):\n    perm = np.random.permutation(TR)\n    for i in range(0, TR, 512):\n        xb = torch.tensor(Xpad[perm[i:i+512]], dtype=torch.long).to(device)\n        yb = torch.tensor(Y[perm[i:i+512]], dtype=torch.long).to(device)\n        opt.zero_grad(); logits = model(xb); l = loss(logits, yb); l.backward(); opt.step()\n    with torch.no_grad():\n        xb = torch.tensor(Xpad[TR:TR+1024], dtype=torch.long).to(device)\n        yb = torch.tensor(Y[TR:TR+1024], dtype=torch.long).to(device)\n        topk = torch.topk(model(xb), k=20, dim=1).indices\n        rec20 = (topk == yb.unsqueeze(1)).any(dim=1).float().mean().item()\n    print(\"epoch\", ep, \"Recall@20\", rec20)"}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}
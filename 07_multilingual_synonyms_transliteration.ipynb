{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# 7) Multilingual Synonyms, Morphology & Transliteration for Query Expansion"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\n%%capture\n!pip -q install --upgrade pip\n!pip -q install datasets transformers sentence-transformers faiss-cpu rank-bm25 torchmetrics scikit-learn lightgbm langdetect unidecode pandas matplotlib tqdm nltk"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\nimport numpy as np, pandas as pd, re\nfrom datasets import load_dataset\nfrom rank_bm25 import BM25Okapi\nfrom nltk.corpus import wordnet as wn\nimport nltk\nfrom unidecode import unidecode\nnltk.download('wordnet')"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\nds = load_dataset(\"amazon_reviews_multi\",\"en\", split=\"train[:10%]\")\ndf = ds.to_pandas()[[\"product_id\",\"review_title\",\"review_body\"]].dropna()\ng = df.groupby(\"product_id\")\ndocs = g.agg({\"review_title\":lambda s:\" | \".join(s.head(10).astype(str)),\n              \"review_body\":lambda s:\" \".join(s.head(5).astype(str))}).reset_index()\ndocs[\"doc_text\"] = (docs[\"review_title\"].fillna(\"\")+\" \"+docs[\"review_body\"].fillna(\"\")).str.strip()\ndocs = docs[docs[\"doc_text\"].str.len()>16].reset_index(drop=True)\npids = set(docs[\"product_id\"])\nqueries = df[df[\"product_id\"].isin(pids)][[\"review_title\",\"product_id\"]].dropna().drop_duplicates().head(3000).reset_index(drop=True)"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\ndef tok(s): return [t for t in re.sub(r\"\\W+\",\" \", str(s).lower()).split() if t]\nbm25 = BM25Okapi([tok(t) for t in docs[\"doc_text\"].tolist()])\npid_by_idx = docs[\"product_id\"].tolist()"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\ndef expand_query_en(q):\n    terms = tok(q); syns=set()\n    for term in terms:\n        for syn in wn.synsets(term):\n            for l in syn.lemmas():\n                s = l.name().replace(\"_\",\" \")\n                if len(s)>2 and s not in terms: syns.add(s)\n    roman = unidecode(q)\n    qexp = q + \" \" + (\" \".join(list(syns)[:5]))\n    if roman.lower()!=q.lower(): qexp += \" \" + roman\n    return qexp\n\ndef eval_recall(qs, k=10, expand=False):\n    hits=0\n    for q,pid in qs[[\"review_title\",\"product_id\"]].itertuples(index=False):\n        qtext = expand_query_en(q) if expand else q\n        s = bm25.get_scores(tok(qtext))\n        top = np.argpartition(s, -k)[-k:]\n        top = top[np.argsort(-s[top])]\n        top_pids = set(docs.iloc[top][\"product_id\"].tolist())\n        if pid in top_pids: hits+=1\n    return hits/len(qs)\n\nr_base = eval_recall(queries.head(1000), 10, expand=False)\nr_exp = eval_recall(queries.head(1000), 10, expand=True)\nprint(f\"Recall@10 baseline={r_base:.3f} | expanded={r_exp:.3f} | lift={(r_exp-r_base):.3f}\")"}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}